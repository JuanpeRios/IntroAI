import numpy as np
from numpy import genfromtxt
import matplotlib.pyplot as plt

class Data(object):

    def __init__(self, dataset):
        self.dataset = dataset

    def split(self, percentage): # 0.8
        X = self.dataset[:,0][::,None]
        y = self.dataset[:,1][::,None]
        permuted_idxs = np.random.permutation(X.shape[0])
        train_idxs = permuted_idxs[0:int(percentage * X.shape[0])]
        test_idxs = permuted_idxs[int(percentage * X.shape[0]): X.shape[0]]
        X_train = X[train_idxs]
        X_test = X[test_idxs]
        y_train = y[train_idxs]
        y_test = y[test_idxs]
        return X_train, X_test, y_train, y_test


class BaseModel(object):

    def __init__(self):
        self.model = None

    def fit(self, X, Y):
        return NotImplemented

    def predict(self, X):
        return NotImplemented

class LinearRegression(BaseModel):

    def fit(self, X, y):
        aux =  np.linalg.inv(np.matmul(X.T,X))
        aux2 = np.matmul(aux,X.T)
        W = np.matmul(aux2,y)
        self.model = W

    def predict(self, X):
        return np.matmul(X,self.model)



class Metric(object):
    def __call__(self, target, prediction):
        return NotImplemented


class MSE(Metric):
    def __call__(self, target, prediction):
        return np.square(np.subtract(target,prediction)).mean()

def k_folds(X_train, y_train, k=5):
    l_regression = LinearRegression()
    error = MSE()
    n,m = np.shape(Xtrain)
    chunk_size = int(n / k)
    mse_list = []
    errormin = 10000000 #Se inicializa la variable para encontrar el mejor modelo en base a MSE
    for i in range(0, n, chunk_size):
        end = i + chunk_size if i + chunk_size <= n else n
        new_X_valid = X_train[i: end]
        new_y_valid = y_train[i: end]
        new_X_train = np.concatenate([X_train[: i], X_train[end:]])
        new_y_train = np.concatenate([y_train[: i], y_train[end:]])

        l_regression.fit(new_X_train, new_y_train)
        prediction = l_regression.predict(new_X_valid)
        mse_list.append(error(new_y_valid, prediction))
        W = np.array(l_regression.model)
        if (error(new_y_valid, prediction)<errormin):  #Se realiza la comparacion de MSE
            Woptimo = W     #Se actualiza el valor optimo del modelo
            errormin = error(new_y_valid, prediction)

    return Woptimo,np.min(mse_list)


def GradienteMiniBatch(Xtrain, Ytrain, lr=0.01, epochs=100):
    """
    shapes:
        X_t = nxm
        y_t = nx1
        W = mx1
    """
    b = 16
    n,m = Xtrain.shape
    Error = MSE()
    ErrorTrain = []
    ErrorVal = []

    # Inicializa W aleatoriamente
    W = np.random.randn(m).reshape(m, 1)
    nuevosdatos = Data(np.vstack((Xtrain.T, Ytrain.T)).T)
    Xtrain, Xval, Ytrain, Yval = nuevosdatos.split(0.8)

    for i in range(epochs):
        idx = np.random.permutation(Xtrain.shape[0])
        Xtrain = Xtrain[idx]
        Ytrain = Ytrain[idx]

        batch_size = int(len(Xtrain) / b)
        for i in range(0, len(Xtrain), batch_size):
            end = i + batch_size if i + batch_size <= len(Xtrain) else len(Xtrain)
            batch_X = Xtrain[i: end]
            batch_y = Ytrain[i: end]

            prediction = np.matmul(batch_X, W)  # bx1
            error = batch_y - prediction  # bx1

            grad_sum = np.sum(error * batch_X, axis=0)
            grad_mul = -2/b * grad_sum  # 1xm
            gradient = np.transpose(grad_mul).reshape(-1, 1)  # mx1

            W = W - (lr * gradient)

        ErrorTrain.append(Error(Xtrain*W,Ytrain))
        ErrorVal.append(Error(Xval*W,Yval))

    plt.plot(range(epochs), ErrorTrain)
    plt.xlabel('Epochs')
    plt.ylabel('MSE Train')
    plt.title('Ejercicio 4.b) Mini Batch. Error Cuadratico Medio en dataset train')
    plt.show()

    plt.plot(range(epochs), ErrorVal)
    plt.xlabel('Epochs')
    plt.ylabel('MSE Validation')
    plt.title('Ejercicio 4.b) Mini Batch. Error Cuadratico Medio en dataset validation')
    plt.show()
    return W

#Ejercicio 2
my_data = genfromtxt('clase_8_dataset.csv', delimiter=',')
Datos = Data(my_data)
Xtrain,Xtest,Ytrain,Ytest = Datos.split(0.8)
print("-----Ejercicio 2-----")
print("Datos separados en 80%-20%")
plt.scatter(my_data[:,0], my_data[:,1], color='b')
plt.title('Dataset')
plt.xlabel('Entrada')
plt.ylabel('Salida')
plt.show()

#Ejercicio 3.a)
modelo1, ecm1 = k_folds(Xtrain,Ytrain,k=5)  #La funcion devuelve el mejor modelo obtenido y su MSE de validacion
print("-----Ejercicio 3.a)-----")
print("El mejor modelo obtenido esta dado con W =",modelo1)
print("Y tiene un error cuadratico medio de validacion de:",ecm1)

#Ejercicio 3.b)
Xtrain2 = np.vstack((np.power(Xtrain, 2).T, Xtrain.T, np.ones(len(Xtrain)))).T
modelo2, ecm2= k_folds(Xtrain2,Ytrain,k=5)
print("-----Ejercicio 3.b)-----")
print("El mejor modelo obtenido para n=2 esta dado con W =",modelo2.T)
print("Y tiene un error cuadratico medio de validacion de:",ecm2)

Xtrain3 = np.vstack((np.power(Xtrain,3).T,np.power(Xtrain, 2).T, Xtrain.T, np.ones(len(Xtrain)))).T
modelo3, ecm3= k_folds(Xtrain3,Ytrain,k=5)
print("El mejor modelo obtenido para n=3 esta dado con W =",modelo3.T)
print("Y tiene un error cuadratico medio de validacion de:",ecm3)

Xtrain4 = np.vstack((np.power(Xtrain,4).T,np.power(Xtrain,3).T,np.power(Xtrain, 2).T, Xtrain.T, np.ones(len(Xtrain)))).T
modelo4, ecm4= k_folds(Xtrain4,Ytrain,k=5)
print("El mejor modelo obtenido para n=4 esta dado con W =",modelo4.T)
print("Y tiene un error cuadratico medio de validacion de:",ecm4)

Xtest2 = np.vstack((np.power(Xtest,2).T, Xtest.T, np.ones(len(Xtest)))).T
Xtest3 = np.vstack((np.power(Xtest,3).T,np.power(Xtest, 2).T, Xtest.T, np.ones(len(Xtest)))).T
Xtest4 = np.vstack((np.power(Xtest,4).T,np.power(Xtest,3).T,np.power(Xtest, 2).T, Xtest.T, np.ones(len(Xtest)))).T
ECM = MSE()
#Se calculan las estimaciones de Y con los distintos modelos y se calcula el MSE de cada uno
Y1est = modelo1*Xtest
Y2est = np.matmul(Xtest2,modelo2)
Y3est = np.matmul(Xtest3,modelo3)
Y4est = np.matmul(Xtest4,modelo4)
error_mod1 = ECM(Y1est,Ytest)
error_mod2 = ECM(Y2est,Ytest)
error_mod3 = ECM(Y3est,Ytest)
error_mod4 = ECM(Y4est,Ytest)

#Ejercicio 3.c)
#Se eligen los mejores modelos
Errores = np.array([error_mod1,error_mod2,error_mod3,error_mod4])
ErrorKFolds = Errores[np.argmin(Errores)]
if np.argmin(Errores)==0:
    Xminibatch = Xtrain
    Y_hat = Y1est
    n = 0
elif np.argmin(Errores)==1:
    Y_hat = Y2est
    Xminibatch = Xtrain2
    n = 2
elif np.argmin(Errores)==2:
    Y_hat = Y3est
    Xminibatch = Xtrain3
    n = 3
elif np.argmin(Errores)==3:
    Y_hat = Y4est
    Xminibatch = Xtrain4
    n = 4
print("Se elige el modelo de n =",n,"porque tiene el MSE mas bajo en el dataset Test y es:",ErrorKFolds)

#Ejercicio 3.d)
plt.scatter(Xtest, Ytest, color='b')
plt.plot(Xtest, Y_hat,'rs')
plt.title('Ejercicio 3.d) Dataset test comparado con el Y estimado')
plt.legend(['Y estimada', 'Dataset Test'])
plt.xlabel('Entrada')
plt.ylabel('Salida')
plt.show()


W = GradienteMiniBatch(Xtrain,Ytrain,lr=0.0000001,epochs=100)
ErrorMiniBatch = ECM(Ytest,np.matmul(Xtest,W))
print("-----Ejercicio 4.c)-----")
if ErrorKFolds>ErrorMiniBatch:
    print("El modelo Mini Batch es mejor que el modelo de Regresion Lineal porque tiene menor MSE")
else:
    print("El modelo de Regresion Lineal es mejor que el modelo Mini Batch porque tiene menor MSE")
